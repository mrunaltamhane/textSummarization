{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d45d9c-b7bd-4c94-9042-c52bad8368a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\mruna\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\mruna\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n",
      "Requirement already satisfied: docx2txt in c:\\users\\mruna\\anaconda3\\lib\\site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453b852f-b26f-4ff9-a020-9c955ee62118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "import docx2txt\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import networkx as nx\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a4b262-bd38-40de-8a02-b336370bce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13563ae4-aca8-4764-bbe9-88fe6e48f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9767abec-5212-474e-91cb-301b70e66155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to show an example of how the method is working\n",
    "# first let's take the document as an input\n",
    "def readDoc():\n",
    "    name = input('Please input a file name: ') \n",
    "    print('You have asked for the document {}'.format(name))\n",
    "\n",
    "    # now read the type of document\n",
    "    if name.lower().endswith('.txt'):\n",
    "        choice = 1\n",
    "    elif name.lower().endswith('.pdf'):\n",
    "        choice = 2\n",
    "    else:\n",
    "        choice = 3\n",
    "        # print(name)\n",
    "    print(choice)\n",
    "    # Case 1: if it is a .txt file\n",
    "        \n",
    "    if choice == 1:\n",
    "        f = open(name, 'r')\n",
    "        document = f.read()\n",
    "        f.close()\n",
    "            \n",
    "    # Case 2: if it is a .pdf file\n",
    "    elif choice == 2:\n",
    "        pdfFileObj = open(name, 'rb')\n",
    "        pdfReader = PdfReader(pdfFileObj)\n",
    "        pageObj = reader.pages(0)\n",
    "        document = pageObj.extractText()\n",
    "        pdfFileObj.close()\n",
    "    \n",
    "    # Case 3: none of the format\n",
    "    else:\n",
    "        print('Failed to load a valid file')\n",
    "        print('Returning an empty string')\n",
    "        document = ''\n",
    "    \n",
    "    print(type(document))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac92371b-1d38-43bc-978a-fbfbcbe87e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractive_summarize(text,per):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    sentence_tokens= [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():                            \n",
    "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
    "    select_length=int(len(sentence_tokens)*per)\n",
    "    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
    "    final_summary=[word.text for word in summary]\n",
    "    summary=''.join(final_summary)\n",
    "    return summary\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fca6a2f-ccd5-4906-bb2d-bfcf69615686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import networkx as nx\n",
    "\n",
    "def extractive_summarize(text):\n",
    "    def tokenize(document):\n",
    "        doc_tokenizer = PunktSentenceTokenizer()\n",
    "        return doc_tokenizer.tokenize(document)\n",
    "    \n",
    "    def process_document(document):\n",
    "        sentences_list = tokenize(document)\n",
    "        cv = CountVectorizer()\n",
    "        cv_matrix = cv.fit_transform(sentences_list)\n",
    "        normal_matrix = TfidfTransformer().fit_transform(cv_matrix)\n",
    "        res_graph = normal_matrix * normal_matrix.T\n",
    "        nx_graph = nx.from_scipy_sparse_matrix(res_graph)\n",
    "        ranks = nx.pagerank(nx_graph)\n",
    "        sentence_array = sorted(((ranks[i], s) for i, s in enumerate(sentences_list)), reverse=True)\n",
    "        sentence_array = np.asarray(sentence_array)\n",
    "        rank_max = float(sentence_array[0][0])\n",
    "        rank_min = float(sentence_array[len(sentence_array) - 1][0])\n",
    "        temp_array = []\n",
    "        \n",
    "        flag = 0\n",
    "        if rank_max - rank_min == 0:\n",
    "            temp_array.append(0)\n",
    "            flag = 1\n",
    "        \n",
    "        if flag != 1:\n",
    "            for i in range(0, len(sentence_array)):\n",
    "                temp_array.append((float(sentence_array[i][0]) - rank_min) / (rank_max - rank_min))\n",
    "        \n",
    "        threshold = (sum(temp_array) / len(temp_array)) + 0.2\n",
    "        sentence_list = []\n",
    "        if len(temp_array) > 1:\n",
    "            for i in range(0, len(temp_array)):\n",
    "                if temp_array[i] > threshold:\n",
    "                        sentence_list.append(sentence_array[i][1])\n",
    "        else:\n",
    "            sentence_list.append(sentence_array[0][1])\n",
    "        \n",
    "        summary = \" \".join(str(x) for x in sentence_list)\n",
    "        return summary\n",
    "    \n",
    "    summary = process_document(text)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1cf46b6-c99c-4984-8769-cb1e9e9ccedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a summarization method:\n",
      "1. Abstractive Summarization\n",
      "2. Extractive Summarization\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  1\n",
      "Please input a file name:  3.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have asked for the document 3.pdf\n",
      "2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_175864\\1295270299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_175864\\1295270299.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadDoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabstractive_summarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.09\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nAbstractive Summary:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_175864\\3546370639.py\u001b[0m in \u001b[0;36mreadDoc\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mpdfFileObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mpdfReader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdfFileObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mpageObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mdocument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpageObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mpdfFileObj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    print(\"Choose a summarization method:\")\n",
    "    print(\"1. Abstractive Summarization\")\n",
    "    print(\"2. Extractive Summarization\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "    if choice == '1':\n",
    "        text = readDoc()\n",
    "        summary = abstractive_summarize(text,0.09)\n",
    "        print(\"\\nAbstractive Summary:\")\n",
    "        print(summary)\n",
    "    elif choice == '2':\n",
    "        text = readDoc()\n",
    "        summary = extractive_summarize(text)\n",
    "        print(\"\\nExtractive Summary:\")\n",
    "        print(summary)\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7f32e-b2a2-4959-85f5-5da3552f660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a19c3-7190-4e44-be30-c6c6a8025664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
