{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d45d9c-b7bd-4c94-9042-c52bad8368a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\mruna\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\mruna\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n",
      "Requirement already satisfied: docx2txt in c:\\users\\mruna\\anaconda3\\lib\\site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "453b852f-b26f-4ff9-a020-9c955ee62118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PyPDF2\n",
    "import docx2txt\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import networkx as nx\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a4b262-bd38-40de-8a02-b336370bce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13563ae4-aca8-4764-bbe9-88fe6e48f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9767abec-5212-474e-91cb-301b70e66155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to show an example of how the method is working\n",
    "# first let's take the document as an input\n",
    "def readDoc():\n",
    "    name = input('Please input a file name: ') \n",
    "    print('You have asked for the document {}'.format(name))\n",
    "\n",
    "    # now read the type of document\n",
    "    if name.lower().endswith('.txt'):\n",
    "        choice = 1\n",
    "    elif name.lower().endswith('.pdf'):\n",
    "        choice = 2\n",
    "    else:\n",
    "        choice = 3\n",
    "        # print(name)\n",
    "    print(choice)\n",
    "    # Case 1: if it is a .txt file\n",
    "        \n",
    "    if choice == 1:\n",
    "        f = open(name, 'r')\n",
    "        document = f.read()\n",
    "        f.close()\n",
    "            \n",
    "    # Case 2: if it is a .pdf file\n",
    "    elif choice == 2:\n",
    "        pdfFileObj = open(name, 'rb')\n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        pageObj = pdfReader.getPage(0)\n",
    "        document = pageObj.extractText()\n",
    "        pdfFileObj.close()\n",
    "    \n",
    "    # Case 3: none of the format\n",
    "    else:\n",
    "        print('Failed to load a valid file')\n",
    "        print('Returning an empty string')\n",
    "        document = ''\n",
    "    \n",
    "    print(type(document))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac92371b-1d38-43bc-978a-fbfbcbe87e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractive_summarize(text,per):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    sentence_tokens= [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():                            \n",
    "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
    "    select_length=int(len(sentence_tokens)*per)\n",
    "    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
    "    final_summary=[word.text for word in summary]\n",
    "    summary=''.join(final_summary)\n",
    "    return summary\n",
    "    # Add your abstractive summarization code here\n",
    "    pass\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fca6a2f-ccd5-4906-bb2d-bfcf69615686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import networkx as nx\n",
    "\n",
    "def extractive_summarize(text):\n",
    "    def tokenize(document):\n",
    "        doc_tokenizer = PunktSentenceTokenizer()\n",
    "        return doc_tokenizer.tokenize(document)\n",
    "    \n",
    "    def process_document(document):\n",
    "        sentences_list = tokenize(document)\n",
    "        cv = CountVectorizer()\n",
    "        cv_matrix = cv.fit_transform(sentences_list)\n",
    "        normal_matrix = TfidfTransformer().fit_transform(cv_matrix)\n",
    "        res_graph = normal_matrix * normal_matrix.T\n",
    "        nx_graph = nx.from_scipy_sparse_matrix(res_graph)\n",
    "        ranks = nx.pagerank(nx_graph)\n",
    "        sentence_array = sorted(((ranks[i], s) for i, s in enumerate(sentences_list)), reverse=True)\n",
    "        sentence_array = np.asarray(sentence_array)\n",
    "        rank_max = float(sentence_array[0][0])\n",
    "        rank_min = float(sentence_array[len(sentence_array) - 1][0])\n",
    "        temp_array = []\n",
    "        \n",
    "        flag = 0\n",
    "        if rank_max - rank_min == 0:\n",
    "            temp_array.append(0)\n",
    "            flag = 1\n",
    "        \n",
    "        if flag != 1:\n",
    "            for i in range(0, len(sentence_array)):\n",
    "                temp_array.append((float(sentence_array[i][0]) - rank_min) / (rank_max - rank_min))\n",
    "        \n",
    "        threshold = (sum(temp_array) / len(temp_array)) + 0.2\n",
    "        sentence_list = []\n",
    "        if len(temp_array) > 1:\n",
    "            for i in range(0, len(temp_array)):\n",
    "                if temp_array[i] > threshold:\n",
    "                        sentence_list.append(sentence_array[i][1])\n",
    "        else:\n",
    "            sentence_list.append(sentence_array[0][1])\n",
    "        \n",
    "        summary = \" \".join(str(x) for x in sentence_list)\n",
    "        return summary\n",
    "    \n",
    "    summary = process_document(text)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1cf46b6-c99c-4984-8769-cb1e9e9ccedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a summarization method:\n",
      "1. Abstractive Summarization\n",
      "2. Extractive Summarization\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  1\n",
      "Please input a file name:  story1.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have asked for the document story1.txt\n",
      "1\n",
      "<class 'str'>\n",
      "\n",
      "Abstractive Summary:\n",
      "People went to Panditji and asked him to\n",
      "give the order for the old woman's oven to be rebuilt and the fire once more\n",
      "lighted, but he paid no attention to them.The village folk customarily have one meal a day of\n",
      "parched grains, so there was always a crowd around Bhungi's oven.\n",
      "Then two servants arrived, each carrying a\n",
      "heaped basket of grain from Pandit Udaybhan with the order to parch it right\n",
      "away.Now when he\n",
      "looked toward the old woman's oven he fell into a violent rage: it was being\n",
      "made again.They began to band together to put out the fire\n",
      "but the sprinkle of water acted like oil on it and the flames kept mounting\n",
      "higher.The names leapt towards the\n",
      "sky, the blaze spread wildly in all directions till the villagers came clustering \n",
      "around this mountain of fire.Pandit Udaybhan's splendid mansion was swallowed up; while he\n",
      "watched, it tossed like a ship amid wild waves and disappeared in the sea of\n",
      "fire.It was already\n",
      "after twelve and even by sunset, she would not have time to parch so much\n",
      "grain.Bhungi was energetically rebuilding it with balls of clay Most\n",
      "likely she'd spent the night at this work and wanted to finish it before the sun\n",
      "was high.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    print(\"Choose a summarization method:\")\n",
    "    print(\"1. Abstractive Summarization\")\n",
    "    print(\"2. Extractive Summarization\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "    if choice == '1':\n",
    "        text = readDoc()\n",
    "        summary = abstractive_summarize(text,0.09)\n",
    "        print(\"\\nAbstractive Summary:\")\n",
    "        print(summary)\n",
    "    elif choice == '2':\n",
    "        text = readDoc()\n",
    "        summary = extractive_summarize(text)\n",
    "        print(\"\\nExtractive Summary:\")\n",
    "        print(summary)\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77f7f32e-b2a2-4959-85f5-5da3552f660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a summarization method:\n",
      "1. Abstractive Summarization\n",
      "2. Extractive Summarization\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  2\n",
      "Please input a file name:  story1.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have asked for the document story1.txt\n",
      "1\n",
      "<class 'str'>\n",
      "\n",
      "Extractive Summary:\n",
      "But on the days when she had to parch grain for Pandit\n",
      "Udaybhan Pandey, the owner of the village, she went to bed hungry. People went to Panditji and asked him to\n",
      "give the order for the old woman's oven to be rebuilt and the fire once more\n",
      "lighted, but he paid no attention to them. He kicked at the trough again but she ran in front of it\n",
      "and took the kick in her side. 'If youâ€™re going to stay in the village you'll have to do my chores. She had to\n",
      "keep stopping from the parching in order to keep the oven fire going. Bhungi was energetically rebuilding it with balls of clay Most\n",
      "likely she'd spent the night at this work and wanted to finish it before the sun\n",
      "was high. With this command the servants went away and Bhungi began to parch the\n",
      "grain. Here she had\n",
      "known the sorrows and pleasures of life; she could not give it up now in the\n",
      "last days. â€˜To his attendants he said, 'Go get a pile of leaves right\n",
      "away and set fire to the whole thing; we'll show her how to make an oven. By now the\n",
      "whole village was in a panic. She would stack the leaves right next to the oven, and after\n",
      "twelve, light the fire. I can't do your work just for the\n",
      "sake of staying in the village. And, for this reason, from time to time the oven\n",
      "was not lit. The result was that that night the oven was dug up and Bhungi was left\n",
      "without a means of livelihood. It was already\n",
      "after twelve and even by sunset, she would not have time to parch so much\n",
      "grain. Now she would have to stay at the oven parching until after dark for\n",
      "no payment. She lived in the Pandit's village, therefore he had full authority to\n",
      "make her do any sort of odd job. He was doing her a favour, in fact, by letting her live in the village at all. They began to band together to put out the fire\n",
      "but the sprinkle of water acted like oil on it and the flames kept mounting\n",
      "higher. No fire was lit in the houses Bhungi's oven was being put to good\n",
      "use today. She knew that she was going against the Pandit's wishes, but she\n",
      "hoped that he had forgotten his anger by then.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mruna\\AppData\\Local\\Temp\\ipykernel_150640\\728693297.py:17: DeprecationWarning: \n",
      "\n",
      "The scipy.sparse array containers will be used instead of matrices\n",
      "in Networkx 3.0. Use `from_scipy_sparse_array` instead.\n",
      "  nx_graph = nx.from_scipy_sparse_matrix(res_graph)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a19c3-7190-4e44-be30-c6c6a8025664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
